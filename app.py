from src.data_loader import load_data, clean_data
from src.feature_selector import run_genetic_selection
from src.model_trainer import train_and_evaluate
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import streamlit as st
import pandas as pd
import numpy as np
import io
import matplotlib.pyplot as plt
import seaborn as sns
import shap

st.set_page_config(
    page_title="å…¥ä¾µåµæ¸¬äº’å‹•å¼åˆ†æç³»çµ±",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

st.title("ğŸ›¡ï¸ å…¥ä¾µåµæ¸¬äº’å‹•å¼åˆ†æç³»çµ±")

DATA_PATH = "data/03-01-2018.csv"

# è¼‰å…¥è³‡æ–™
df_raw = load_data(DATA_PATH)

if df_raw is not None:
    # åœ¨æ¸…ç†å‰ï¼Œå¼·åˆ¶å°‡æ‰€æœ‰ç‰¹å¾µæ¬„ä½è½‰æ›ç‚ºæ•¸å€¼ï¼Œç„¡æ³•è½‰æ›çš„æœƒè®Šæˆ NaN
    feature_cols = df_raw.columns.drop(['Label', 'Timestamp'])
    for col in feature_cols:
        df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce')

    st.success(f"æˆåŠŸè¼‰å…¥åŸå§‹è³‡æ–™é›†ï¼Œå…± {df_raw.shape[0]} ç­†è¨˜éŒ„ï¼Œ{df_raw.shape[1]} å€‹æ¬„ä½ã€‚")
    
    # æ¸…ç†è³‡æ–™ï¼ˆç¾åœ¨ä¹Ÿèƒ½ç§»é™¤ä¸Šé¢æ­¥é©Ÿç”¢ç”Ÿçš„ NaNï¼‰
    df_cleaned = clean_data(df_raw.copy()) # ä½¿ç”¨ copy é¿å…ä¿®æ”¹åˆ°å¿«å–ä¸­çš„åŸå§‹è³‡æ–™

    st.write("---")
    st.header("**ç›®æ¨™è®Šæ•¸ (Label) åˆ†æ**")
    label_counts = df_cleaned['Label'].value_counts()
    st.write("å„é¡åˆ¥è³‡æ–™ç­†æ•¸ï¼š")
    st.write(label_counts)

    st.subheader("ç›®æ¨™è®Šæ•¸åˆ†ä½ˆåœ–")
    st.bar_chart(label_counts)
    
    st.info("å¾ä¸Šåœ–å¯çŸ¥ï¼Œè³‡æ–™é›†å­˜åœ¨åš´é‡çš„é¡åˆ¥ä¸å¹³è¡¡å•é¡Œï¼Œ'Benign' (æ­£å¸¸) æµé‡é å¤šæ–¼å„é¡æ”»æ“Šæµé‡ã€‚é€™åœ¨å¾ŒçºŒæ¨¡å‹è©•ä¼°æ™‚éœ€è¦ç‰¹åˆ¥æ³¨æ„ã€‚")

    st.write("---")
    st.header("ç‰¹å¾µé¸æ“‡ (ä½¿ç”¨åŸºå› æ¼”ç®—æ³•)")

    if st.button("ğŸš€ é–‹å§‹ç‰¹å¾µé¸æ“‡"):
        # 1. è³‡æ–™é è™•ç†
        with st.spinner("æ­£åœ¨é€²è¡Œè³‡æ–™é è™•ç†..."):
            # åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™
            X = df_cleaned.drop(columns=['Label', 'Timestamp'])
            y = df_cleaned['Label']

            # å°‡ç›®æ¨™è®Šæ•¸é€²è¡Œç·¨ç¢¼
            le = LabelEncoder()
            y_encoded = le.fit_transform(y)

            # å°ç‰¹å¾µé€²è¡Œæ¨™æº–åŒ–
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
            st.session_state['scaler'] = scaler # å„²å­˜ scaler
        st.success("è³‡æ–™é è™•ç†å®Œæˆï¼")

        # 2. åŸ·è¡ŒåŸºå› æ¼”ç®—æ³•
        selected_features, best_score = run_genetic_selection(X_scaled, y_encoded)

        # 3. é¡¯ç¤ºçµæœ
        st.subheader("åŸºå› æ¼”ç®—æ³•é¸æ“‡çµæœ")
        st.success(f"æ¼”ç®—æ³•åŸ·è¡Œå®Œç•¢ï¼æœ€ä½³åˆ†æ•¸ (Accuracy): {best_score:.4f}")
        st.metric(label="é¸æ“‡çš„ç‰¹å¾µæ•¸é‡", value=f"{len(selected_features)} / {len(X.columns)}")
        
        st.write("**é¸æ“‡çš„ç‰¹å¾µåˆ—è¡¨ï¼š**")
        st.dataframe(selected_features)

        # å°‡çµæœå„²å­˜åˆ° session state ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨
        st.session_state['selection_done'] = True
        st.session_state['selected_features'] = selected_features
        st.session_state['X_scaled'] = X_scaled
        st.session_state['y_encoded'] = y_encoded
        st.session_state['le'] = le

    st.write("---")

    # --- æ¨¡å‹è¨“ç·´å€å¡Š ---
    if st.session_state.get('selection_done', False):
        st.header("3. æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°")
        if st.button("ğŸ§  ä½¿ç”¨é¸å®šç‰¹å¾µé€²è¡Œæ¨¡å‹è¨“ç·´"):
            with st.spinner("æ­£åœ¨æº–å‚™è¨“ç·´è³‡æ–™..."):
                X_selected = st.session_state['X_scaled'][st.session_state['selected_features']]
                y_encoded = st.session_state['y_encoded']
                le = st.session_state['le']

                X_train, X_test, y_train, y_test = train_test_split(
                    X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
                )
            st.success("è³‡æ–™åˆ†å‰²å®Œæˆ (80% è¨“ç·´, 20% æ¸¬è©¦)ï¼")

            # è¨“ç·´ä¸¦è©•ä¼°
            metrics, model, cm_df = train_and_evaluate(X_train, X_test, y_train, y_test, le.classes_)
            st.session_state['trained_model'] = model # å„²å­˜è¨“ç·´å¥½çš„æ¨¡å‹

            with st.spinner("å»ºç«‹ SHAP è§£é‡‹å™¨..."):
                explainer = shap.TreeExplainer(model)
                st.session_state['shap_explainer'] = explainer

            # é¡¯ç¤ºè©•ä¼°æŒ‡æ¨™
            st.subheader("æ¨¡å‹è©•ä¼°æŒ‡æ¨™")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("Accuracy", f"{metrics['accuracy']:.4f}")
            col2.metric("Precision", f"{metrics['precision']:.4f}")
            col3.metric("Recall", f"{metrics['recall']:.4f}")
            col4.metric("F1-Score", f"{metrics['f1_score']:.4f}")

            st.subheader("æ··æ·†çŸ©é™£ (Confusion Matrix)")
            st.info("æ··æ·†çŸ©é™£é¡¯ç¤ºæ¨¡å‹åœ¨å„é¡åˆ¥ä¸Šçš„é æ¸¬è¡¨ç¾ã€‚å°è§’ç·šä¸Šçš„æ•¸å­—ä»£è¡¨æ­£ç¢ºé æ¸¬çš„æ•¸é‡ï¼Œéå°è§’ç·šå‰‡ä»£è¡¨éŒ¯èª¤é æ¸¬çš„æ•¸é‡ã€‚")
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_title('Confusion Matrix')
            ax.set_xlabel('Predicted Label')
            ax.set_ylabel('True Label')
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            plt.tight_layout()
            st.pyplot(fig)
    
    st.write("---")

    # --- å³æ™‚é æ¸¬å€å¡Š ---
    if st.session_state.get('trained_model'):
        st.header("4. å³æ™‚é æ¸¬")
        st.write("è«‹è¼¸å…¥ä»¥ä¸‹ç‰¹å¾µå€¼ï¼Œä¾†æ¨¡æ“¬ä¸€ç­†æ–°çš„ç¶²è·¯æµé‡æ•¸æ“šï¼š")

        selected_features = st.session_state['selected_features']
        
        with st.form(key='prediction_form'):
            # å»ºç«‹å¤šåˆ—è¼¸å…¥
            num_cols = 4
            cols = st.columns(num_cols)
            user_inputs = {}
            for i, feature in enumerate(selected_features):
                with cols[i % num_cols]:
                    user_inputs[feature] = st.number_input(label=feature, value=0.0, format="%.4f")
            
            submit_button = st.form_submit_button(label='âš¡ åŸ·è¡Œé æ¸¬')

        if submit_button:
            # æ”¶é›†ä½¿ç”¨è€…è¼¸å…¥çš„è³‡æ–™ (åªåŒ…å« selected_features)
            input_df_user = pd.DataFrame([user_inputs])

            # å–å¾— scaler, model, le
            scaler = st.session_state['scaler']
            model = st.session_state['trained_model']
            le = st.session_state['le']
            
            # å–å¾— scaler è¨“ç·´æ™‚æ‰€éœ€çš„æ‰€æœ‰ç‰¹å¾µæ¬„ä½
            required_features_for_scaler = scaler.feature_names_in_
            
            # å»ºç«‹ä¸€å€‹ç¬¦åˆ scaler è¼¸å…¥è¦æ±‚çš„å®Œæ•´ DataFrameï¼Œé è¨­å€¼ç‚º 0
            input_df_full = pd.DataFrame(0.0, index=[0], columns=required_features_for_scaler)
            
            # å°‡ä½¿ç”¨è€…çš„è¼¸å…¥å¡«å…¥å°æ‡‰çš„æ¬„ä½
            for col in input_df_user.columns:
                if col in input_df_full.columns:
                    input_df_full[col] = input_df_user[col].values

            # ä½¿ç”¨ scaler å°å®Œæ•´çš„è³‡æ–™é€²è¡Œç¸®æ”¾
            input_scaled_full = scaler.transform(input_df_full)
            
            # å°‡ç¸®æ”¾å¾Œçš„ numpy array è½‰å› DataFrameï¼Œä¸¦åŠ ä¸Šæ¬„ä½åç¨±
            input_scaled_df = pd.DataFrame(input_scaled_full, columns=required_features_for_scaler)
            
            # å¾ç¸®æ”¾å¾Œçš„å®Œæ•´è³‡æ–™ä¸­ï¼Œç¯©é¸å‡ºæ¨¡å‹è¨“ç·´æ™‚ä½¿ç”¨çš„ç‰¹å¾µ
            final_input_for_model = input_scaled_df[st.session_state['selected_features']]

            # é æ¸¬
            prediction = model.predict(final_input_for_model)

            # è§£ç¢¼çµæœ
            predicted_label = le.inverse_transform(prediction)[0]

            st.subheader("é æ¸¬çµæœ")
            if predicted_label == 'Benign':
                st.success(f"âœ… é æ¸¬çµæœï¼š **{predicted_label}** (æ­£å¸¸)")
            else:
                st.error(f"ğŸš¨ é æ¸¬çµæœï¼š **{predicted_label}** (æ”»æ“Š!)")

            # --- SHAP è§£é‡‹ ---
            st.subheader("æ¨¡å‹é æ¸¬è§£é‡‹ (SHAP Analysis)")
            st.info("ä¸‹åœ–é¡¯ç¤ºäº†å„å€‹ç‰¹å¾µå¦‚ä½•å°‡é æ¸¬çµæœå¾åŸºæº–å€¼ï¼ˆBase valueï¼‰æ¨å‘æœ€çµ‚çš„é æ¸¬å€¼ã€‚ç´…è‰²ç‰¹å¾µå¢åŠ äº†é æ¸¬ç‚ºè©²é¡åˆ¥çš„æ©Ÿç‡ï¼Œè—è‰²ç‰¹å¾µå‰‡é™ä½äº†æ©Ÿç‡ã€‚")

            with st.spinner("æ­£åœ¨è¨ˆç®— SHAP å€¼..."):
                try:
                    explainer = st.session_state['shap_explainer']
                    shap_values = explainer.shap_values(final_input_for_model)
                    predicted_class_index = prediction[0]

                    # Handle both multi-class and binary classification outputs from SHAP
                    if isinstance(explainer.expected_value, (list, np.ndarray)):
                        # Multi-class case
                        shap_base_value = explainer.expected_value[predicted_class_index]
                        shap_values_for_class = shap_values[predicted_class_index][0]
                    else:
                        # Binary case
                        shap_base_value = explainer.expected_value
                        shap_values_for_class = shap_values[0]
                    
                    # ç¹ªè£½ SHAP force plot
                    st.write(f"**å°æ–¼é¡åˆ¥ `{predicted_label}` çš„è§£é‡‹ï¼š**")
                    fig, ax = plt.subplots(figsize=(20, 4))
                    shap.force_plot(
                        shap_base_value,
                        shap_values_for_class,
                        final_input_for_model.iloc[0],
                        matplotlib=True,
                        show=False,
                        text_rotation=15
                    )
                    plt.tight_layout()
                    st.pyplot(fig, bbox_inches='tight')
                    plt.close(fig)
                except Exception as e:
                    st.warning(f"ç„¡æ³•ç”¢ç”Ÿ SHAP åˆ†æåœ–ï¼š{e}")

    st.write("---")

    # --- æ‰¹æ¬¡é æ¸¬å€å¡Š (å«æ¬„ä½æ˜ å°„) ---
    if st.session_state.get('trained_model'):
        st.header("5. æ‰¹æ¬¡æµé‡åˆ†æ (ä¸Šå‚³ CSV)")
        st.write("ä¸Šå‚³åŒ…å«å¤šç­†ç¶²è·¯æµé‡çš„ CSV æª”ï¼Œç³»çµ±å°‡é€ç­†åˆ†æä¸¦åˆ¤æ–·æ˜¯å¦ç‚ºæ”»æ“Šã€‚")

        selected_features = st.session_state['selected_features']
        template_df = pd.DataFrame(columns=selected_features)
        csv_template = template_df.to_csv(index=False).encode('utf-8')

        st.download_button(
            label="ä¸‹è¼‰åˆ†æç¯„ä¾‹ CSV æª”æ¡ˆ",
            data=csv_template,
            file_name="prediction_template.csv",
            mime="text/csv",
            help="ä¸‹è¼‰ä¸€å€‹åŒ…å«æ‰€æœ‰é¸å®šç‰¹å¾µæ¬„ä½çš„ç©ºç™½ CSV æª”æ¡ˆï¼Œæ‚¨å¯ä»¥å¡«å…¥æ•¸æ“šå¾Œä¸Šå‚³ã€‚"
        )

        uploaded_file = st.file_uploader("ä¸Šå‚³å¾…åˆ†æçš„ CSV æª”æ¡ˆ", type=["csv"])

        if uploaded_file is not None:
            # --- STATE MANAGEMENT ---
            # If a new file is uploaded, clear old analysis results
            if 'current_file_name' not in st.session_state or st.session_state.current_file_name != uploaded_file.name:
                st.session_state.current_file_name = uploaded_file.name
                if 'batch_results_df' in st.session_state:
                    del st.session_state['batch_results_df']
            # --- END STATE MANAGEMENT ---

            try:
                batch_df_raw = pd.read_csv(uploaded_file)
                # Replace infinite values with NaN to prevent scaler errors
                batch_df_raw.replace([np.inf, -np.inf], np.nan, inplace=True)
                
                with st.expander("é»æ­¤æŸ¥çœ‹ä¸Šå‚³çš„åŸå§‹è³‡æ–™ (å‰ 5 ç­†)"):
                    st.dataframe(batch_df_raw.head())

                selected_features = st.session_state['selected_features']
                uploaded_columns = batch_df_raw.columns.tolist()

                st.subheader("æ¬„ä½æ˜ å°„è¨­å®š")
                st.info("è«‹å°‡æ¨¡å‹æ‰€éœ€çš„ç‰¹å¾µï¼Œæ˜ å°„åˆ°æ‚¨ä¸Šå‚³æª”æ¡ˆä¸­å°æ‡‰çš„æ¬„ä½ã€‚å¦‚æœæŸå€‹ç‰¹å¾µåœ¨æ‚¨çš„æª”æ¡ˆä¸­ä¸å­˜åœ¨ï¼Œè«‹é¸æ“‡ 'æœªæ˜ å°„'ï¼Œç³»çµ±å°‡ä½¿ç”¨é è¨­å€¼ 0 å¡«å……ã€‚")

                column_mapping = {}
                mapping_cols = st.columns(4)
                for i, feature in enumerate(selected_features):
                    with mapping_cols[i % 4]:
                        default_index = uploaded_columns.index(feature) if feature in uploaded_columns else 0
                        column_mapping[feature] = st.selectbox(
                            f"æ¨¡å‹ç‰¹å¾µ: {feature}",
                            ['æœªæ˜ å°„'] + uploaded_columns,
                            index=default_index + 1 if feature in uploaded_columns else 0,
                            key=f"map_{feature}"
                        )
                
                if st.button("ğŸš€ é–‹å§‹åˆ†ææµé‡"):
                    with st.spinner("æ­£åœ¨æ ¹æ“šæ˜ å°„è¨­å®šè™•ç†è³‡æ–™ä¸¦é€²è¡Œåˆ†æ..."):
                        # å»ºç«‹ä¸€å€‹åªåŒ…å«ä½¿ç”¨è€…æ˜ å°„æ¬„ä½çš„ DataFrame
                        batch_X_mapped_user = pd.DataFrame(0.0, index=batch_df_raw.index, columns=selected_features)

                        for model_feature, uploaded_col in column_mapping.items():
                            if uploaded_col != 'æœªæ˜ å°„':
                                batch_X_mapped_user[model_feature] = pd.to_numeric(batch_df_raw[uploaded_col], errors='coerce')
                        
                        # è™•ç† NaN å€¼
                        batch_X_mapped_user.dropna(inplace=True)

                        if batch_X_mapped_user.empty:
                            st.warning("é è™•ç†å¾Œï¼Œä¸Šå‚³æª”æ¡ˆä¸­æ²’æœ‰æœ‰æ•ˆè³‡æ–™å¯ä¾›åˆ†æã€‚è«‹æª¢æŸ¥æ‚¨çš„æ˜ å°„å’Œæ•¸æ“šã€‚")
                            # If empty, make sure we don't show old results
                            if 'batch_results_df' in st.session_state:
                                del st.session_state['batch_results_df']
                        else:
                            # --- START OF PREDICTION LOGIC ---
                            scaler = st.session_state['scaler']
                            model = st.session_state['trained_model']
                            le = st.session_state['le']
                            
                            required_features_for_scaler = scaler.feature_names_in_
                            
                            batch_df_full = pd.DataFrame(0.0, index=batch_X_mapped_user.index, columns=required_features_for_scaler)
                            
                            for col in batch_X_mapped_user.columns:
                                if col in batch_df_full.columns:
                                    batch_df_full[col] = batch_X_mapped_user[col]

                            batch_scaled_full = scaler.transform(batch_df_full)
                            
                            batch_scaled_df = pd.DataFrame(batch_scaled_full, index=batch_df_full.index, columns=required_features_for_scaler)
                            
                            final_batch_for_model = batch_scaled_df[st.session_state['selected_features']]
                            
                            # --- STORE SCALED DATA FOR SHAP ---
                            st.session_state['final_batch_for_model'] = final_batch_for_model
                            # --- END ---

                            batch_predictions_encoded = model.predict(final_batch_for_model)

                            batch_predictions_label = le.inverse_transform(batch_predictions_encoded)

                            batch_df_results = batch_df_raw.loc[final_batch_for_model.index].copy()
                            batch_df_results['Predicted_Label'] = batch_predictions_label
                            
                            batch_df_results['åˆ†æçµæœ'] = batch_df_results['Predicted_Label'].apply(lambda x: 'æ”»æ“Š' if x != 'Benign' else 'æ­£å¸¸')
                            
                            # --- STORE RESULTS IN SESSION STATE ---
                            st.session_state['batch_results_df'] = batch_df_results

            except Exception as e:
                st.error(f"è™•ç†ä¸Šå‚³æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                if 'batch_results_df' in st.session_state:
                    del st.session_state['batch_results_df']

            # --- DISPLAY RESULTS (MOVED OUTSIDE THE BUTTON LOGIC) ---
            if 'batch_results_df' in st.session_state:
                batch_df_results = st.session_state['batch_results_df']
                
                st.subheader("ğŸ“Š åˆ†æçµæœç¸½è¦½")
                prediction_counts = batch_df_results['åˆ†æçµæœ'].value_counts()
                st.bar_chart(prediction_counts)

                st.subheader("ğŸ“„ è©³ç´°åˆ†æçµæœ")
                filter_option = st.radio(
                    "ç¯©é¸é¡¯ç¤ºçµæœï¼š",
                    ('é¡¯ç¤ºå…¨éƒ¨', 'åƒ…é¡¯ç¤ºæ”»æ“Š', 'åƒ…é¡¯ç¤ºæ­£å¸¸'),
                    horizontal=True,
                    key='filter_radio'
                )

                if filter_option == 'åƒ…é¡¯ç¤ºæ”»æ“Š':
                    filtered_df = batch_df_results[batch_df_results['åˆ†æçµæœ'] == 'æ”»æ“Š']
                elif filter_option == 'åƒ…é¡¯ç¤ºæ­£å¸¸':
                    filtered_df = batch_df_results[batch_df_results['åˆ†æçµæœ'] == 'æ­£å¸¸']
                else:
                    filtered_df = batch_df_results

                if filtered_df.empty:
                    st.info("åœ¨ç›®å‰çš„ç¯©é¸æ¢ä»¶ä¸‹ï¼Œæ²’æœ‰å¯é¡¯ç¤ºçš„è³‡æ–™ã€‚")
                else:
                    final_cols = ['åˆ†æçµæœ', 'Predicted_Label'] + [col for col in batch_df_raw.columns if col not in ['åˆ†æçµæœ', 'Predicted_Label']]
                    st.dataframe(filtered_df[final_cols])
                    csv_results = filtered_df[final_cols].to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ç›®å‰çš„åˆ†æçµæœ",
                        data=csv_results,
                        file_name="traffic_analysis_results.csv",
                        mime="text/csv"
                    )

                # --- SHAP Drill-down Analysis ---
                st.subheader("ğŸ”¬ æ·±å…¥åˆ†æå–®ç­†æ”»æ“Šæµé‡ (SHAP Drill-down)")
                
                attack_df = batch_df_results[batch_df_results['åˆ†æçµæœ'] == 'æ”»æ“Š']
                if attack_df.empty:
                    st.info("åœ¨ç›®å‰çš„åˆ†æçµæœä¸­ï¼Œæ²’æœ‰åµæ¸¬åˆ°æ”»æ“Šæµé‡å¯ä¾›æ·±å…¥åˆ†æã€‚")
                else:
                    st.write("å¾è¢«æ¨™è¨˜ç‚ºã€Œæ”»æ“Šã€çš„æµé‡ä¸­é¸æ“‡ä¸€ç­†ï¼ŒæŸ¥çœ‹æ¨¡å‹çš„åˆ¤æ–·ä¾æ“šã€‚")
                    selected_index = st.selectbox(
                        "é¸æ“‡ä¸€ç­†æ”»æ“Šæµé‡çš„ç´¢å¼• (Index) é€²è¡Œåˆ†æï¼š",
                        options=attack_df.index
                    )

                    if selected_index is not None:
                        with st.spinner("æ­£åœ¨ç‚ºæ‚¨é¸æ“‡çš„æµé‡ç”¢ç”Ÿ SHAP åˆ†æåœ–..."):
                            try:
                                explainer = st.session_state['shap_explainer']
                                final_batch_for_model = st.session_state['final_batch_for_model']
                                le = st.session_state['le']

                                # å–å¾—è©²ç­†æµé‡çš„è³‡æ–™èˆ‡é æ¸¬çµæœ
                                single_instance = final_batch_for_model.loc[[selected_index]]
                                single_prediction_label = batch_df_results.loc[selected_index, 'Predicted_Label']
                                single_prediction_index = list(le.classes_).index(single_prediction_label)

                                # è¨ˆç®— SHAP å€¼
                                shap_values = explainer.shap_values(single_instance)

                                # Handle both multi-class and binary classification outputs from SHAP
                                if isinstance(explainer.expected_value, (list, np.ndarray)):
                                    # Multi-class case
                                    shap_base_value = explainer.expected_value[single_prediction_index]
                                    shap_values_for_class = shap_values[single_prediction_index][0]
                                else:
                                    # Binary case
                                    shap_base_value = explainer.expected_value
                                    shap_values_for_class = shap_values[0]

                                # ç¹ªè£½ SHAP force plot
                                st.write(f"**å°æ–¼ç´¢å¼• `{selected_index}`ï¼Œé¡åˆ¥ `{single_prediction_label}` çš„è§£é‡‹ï¼š**")
                                fig, ax = plt.subplots(figsize=(20, 4))
                                shap.force_plot(
                                    shap_base_value,
                                    shap_values_for_class,
                                    single_instance.iloc[0],
                                    matplotlib=True,
                                    show=False,
                                    text_rotation=15
                                )
                                plt.tight_layout()
                                st.pyplot(fig, bbox_inches='tight')
                                plt.close(fig)

                            except KeyError:
                                st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼šç„¡æ³•åœ¨å·²è™•ç†çš„è³‡æ–™ä¸­æ‰¾åˆ°ç´¢å¼• {selected_index}ã€‚é€™å¯èƒ½æ˜¯å› ç‚ºè©²ç­†è³‡æ–™åœ¨ä¸Šå‚³å¾Œå› åŒ…å«ç„¡æ•ˆå€¼è€Œè¢«ç§»é™¤ã€‚è«‹å˜—è©¦é¸æ“‡å¦ä¸€ç­†æµé‡ã€‚")
                            except Exception as e:
                                st.warning(f"ç„¡æ³•ç”¢ç”Ÿ SHAP åˆ†æåœ–ï¼š{e}")

    st.write("---")
    if st.checkbox("é¡¯ç¤ºæ¸…ç†å¾Œçš„è³‡æ–™æ‘˜è¦"):
        st.subheader("è³‡æ–™é è¦½ (å‰ 5 ç­†)")
        st.write(df_cleaned.head())

        st.subheader("è³‡æ–™åŸºæœ¬è³‡è¨Š")
        buffer = io.StringIO()
        df_cleaned.info(buf=buffer)
        s = buffer.getvalue()
        st.text(s)

        st.subheader("æ•¸å€¼ç‰¹å¾µçµ±è¨ˆæ‘˜è¦")
        st.write(df_cleaned.describe())
else:
    st.warning("è«‹ç¢ºèª `03-01-2018.csv` å·²æ”¾ç½®åœ¨ `data` è³‡æ–™å¤¾ä¸­ã€‚")