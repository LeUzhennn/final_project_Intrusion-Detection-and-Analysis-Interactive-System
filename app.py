from src.data_loader import load_data, clean_data
from src.feature_selector import run_genetic_selection
from src.model_trainer import train_and_evaluate
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import streamlit as st
import pandas as pd
import io

st.set_page_config(
    page_title="å…¥ä¾µåµæ¸¬äº’å‹•å¼åˆ†æç³»çµ±",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

st.title("ğŸ›¡ï¸ å…¥ä¾µåµæ¸¬äº’å‹•å¼åˆ†æç³»çµ±")

DATA_PATH = "data/03-01-2018.csv"

# è¼‰å…¥è³‡æ–™
df_raw = load_data(DATA_PATH)

if df_raw is not None:
    # åœ¨æ¸…ç†å‰ï¼Œå¼·åˆ¶å°‡æ‰€æœ‰ç‰¹å¾µæ¬„ä½è½‰æ›ç‚ºæ•¸å€¼ï¼Œç„¡æ³•è½‰æ›çš„æœƒè®Šæˆ NaN
    feature_cols = df_raw.columns.drop(['Label', 'Timestamp'])
    for col in feature_cols:
        df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce')

    st.success(f"æˆåŠŸè¼‰å…¥åŸå§‹è³‡æ–™é›†ï¼Œå…± {df_raw.shape[0]} ç­†è¨˜éŒ„ï¼Œ{df_raw.shape[1]} å€‹æ¬„ä½ã€‚")
    
    # æ¸…ç†è³‡æ–™ï¼ˆç¾åœ¨ä¹Ÿèƒ½ç§»é™¤ä¸Šé¢æ­¥é©Ÿç”¢ç”Ÿçš„ NaNï¼‰
    df_cleaned = clean_data(df_raw.copy()) # ä½¿ç”¨ copy é¿å…ä¿®æ”¹åˆ°å¿«å–ä¸­çš„åŸå§‹è³‡æ–™

    st.write("---")
    st.header("**ç›®æ¨™è®Šæ•¸ (Label) åˆ†æ**")
    label_counts = df_cleaned['Label'].value_counts()
    st.write("å„é¡åˆ¥è³‡æ–™ç­†æ•¸ï¼š")
    st.write(label_counts)

    st.subheader("ç›®æ¨™è®Šæ•¸åˆ†ä½ˆåœ–")
    st.bar_chart(label_counts)
    
    st.info("å¾ä¸Šåœ–å¯çŸ¥ï¼Œè³‡æ–™é›†å­˜åœ¨åš´é‡çš„é¡åˆ¥ä¸å¹³è¡¡å•é¡Œï¼Œ'Benign' (æ­£å¸¸) æµé‡é å¤šæ–¼å„é¡æ”»æ“Šæµé‡ã€‚é€™åœ¨å¾ŒçºŒæ¨¡å‹è©•ä¼°æ™‚éœ€è¦ç‰¹åˆ¥æ³¨æ„ã€‚")

    st.write("---")
    st.header("ç‰¹å¾µé¸æ“‡ (ä½¿ç”¨åŸºå› æ¼”ç®—æ³•)")

    if st.button("ğŸš€ é–‹å§‹ç‰¹å¾µé¸æ“‡"):
        # 1. è³‡æ–™é è™•ç†
        with st.spinner("æ­£åœ¨é€²è¡Œè³‡æ–™é è™•ç†..."):
            # åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™
            X = df_cleaned.drop(columns=['Label', 'Timestamp'])
            y = df_cleaned['Label']

            # å°‡ç›®æ¨™è®Šæ•¸é€²è¡Œç·¨ç¢¼
            le = LabelEncoder()
            y_encoded = le.fit_transform(y)

            # å°ç‰¹å¾µé€²è¡Œæ¨™æº–åŒ–
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
            st.session_state['scaler'] = scaler # å„²å­˜ scaler
        st.success("è³‡æ–™é è™•ç†å®Œæˆï¼")

        # 2. åŸ·è¡ŒåŸºå› æ¼”ç®—æ³•
        selected_features, best_score = run_genetic_selection(X_scaled, y_encoded)

        # 3. é¡¯ç¤ºçµæœ
        st.subheader("åŸºå› æ¼”ç®—æ³•é¸æ“‡çµæœ")
        st.success(f"æ¼”ç®—æ³•åŸ·è¡Œå®Œç•¢ï¼æœ€ä½³åˆ†æ•¸ (Accuracy): {best_score:.4f}")
        st.metric(label="é¸æ“‡çš„ç‰¹å¾µæ•¸é‡", value=f"{len(selected_features)} / {len(X.columns)}")
        
        st.write("**é¸æ“‡çš„ç‰¹å¾µåˆ—è¡¨ï¼š**")
        st.dataframe(selected_features)

        # å°‡çµæœå„²å­˜åˆ° session state ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨
        st.session_state['selection_done'] = True
        st.session_state['selected_features'] = selected_features
        st.session_state['X_scaled'] = X_scaled
        st.session_state['y_encoded'] = y_encoded
        st.session_state['le'] = le

    st.write("---")

    # --- æ¨¡å‹è¨“ç·´å€å¡Š ---
    if st.session_state.get('selection_done', False):
        st.header("3. æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°")
        if st.button("ğŸ§  ä½¿ç”¨é¸å®šç‰¹å¾µé€²è¡Œæ¨¡å‹è¨“ç·´"):
            with st.spinner("æ­£åœ¨æº–å‚™è¨“ç·´è³‡æ–™..."):
                X_selected = st.session_state['X_scaled'][st.session_state['selected_features']]
                y_encoded = st.session_state['y_encoded']
                le = st.session_state['le']

                X_train, X_test, y_train, y_test = train_test_split(
                    X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
                )
            st.success("è³‡æ–™åˆ†å‰²å®Œæˆ (80% è¨“ç·´, 20% æ¸¬è©¦)ï¼")

            # è¨“ç·´ä¸¦è©•ä¼°
            metrics, model = train_and_evaluate(X_train, X_test, y_train, y_test, le.classes_)
            st.session_state['trained_model'] = model # å„²å­˜è¨“ç·´å¥½çš„æ¨¡å‹

            # é¡¯ç¤ºè©•ä¼°æŒ‡æ¨™
            st.subheader("æ¨¡å‹è©•ä¼°æŒ‡æ¨™")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("Accuracy", f"{metrics['accuracy']:.4f}")
            col2.metric("Precision", f"{metrics['precision']:.4f}")
            col3.metric("Recall", f"{metrics['recall']:.4f}")
            col4.metric("F1-Score", f"{metrics['f1_score']:.4f}")
    
    st.write("---")

    # --- å³æ™‚é æ¸¬å€å¡Š ---
    if st.session_state.get('trained_model'):
        st.header("4. å³æ™‚é æ¸¬")
        st.write("è«‹è¼¸å…¥ä»¥ä¸‹ç‰¹å¾µå€¼ï¼Œä¾†æ¨¡æ“¬ä¸€ç­†æ–°çš„ç¶²è·¯æµé‡æ•¸æ“šï¼š")

        selected_features = st.session_state['selected_features']
        
        with st.form(key='prediction_form'):
            # å»ºç«‹å¤šåˆ—è¼¸å…¥
            num_cols = 4
            cols = st.columns(num_cols)
            user_inputs = {}
            for i, feature in enumerate(selected_features):
                with cols[i % num_cols]:
                    user_inputs[feature] = st.number_input(label=feature, value=0.0, format="%.4f")
            
            submit_button = st.form_submit_button(label='âš¡ åŸ·è¡Œé æ¸¬')

        if submit_button:
            # æ”¶é›†è³‡æ–™
            input_df = pd.DataFrame([user_inputs])

            # ç¸®æ”¾è³‡æ–™
            scaler = st.session_state['scaler']
            input_scaled = scaler.transform(input_df)

            # é æ¸¬
            model = st.session_state['trained_model']
            prediction = model.predict(input_scaled)

            # è§£ç¢¼çµæœ
            le = st.session_state['le']
            predicted_label = le.inverse_transform(prediction)[0]

            st.subheader("é æ¸¬çµæœ")
            if predicted_label == 'Benign':
                st.success(f"âœ… é æ¸¬çµæœï¼š **{predicted_label}** (æ­£å¸¸)")
            else:
                st.error(f"ğŸš¨ é æ¸¬çµæœï¼š **{predicted_label}** (æ”»æ“Š!)")

    st.write("---")

    # --- æ‰¹æ¬¡é æ¸¬å€å¡Š (å«æ¬„ä½æ˜ å°„) ---
    if st.session_state.get('trained_model'):
        st.header("5. æ‰¹æ¬¡é æ¸¬ (ä¸Šå‚³ CSV æª”æ¡ˆä¸¦æ˜ å°„æ¬„ä½)")
        st.write("è«‹ä¸Šå‚³æ‚¨çš„ CSV æª”æ¡ˆï¼Œä¸¦å°‡å…¶æ¬„ä½æ˜ å°„åˆ°æ¨¡å‹æ‰€éœ€çš„ç‰¹å¾µã€‚")

        selected_features = st.session_state['selected_features']
        template_df = pd.DataFrame(columns=selected_features)
        csv_template = template_df.to_csv(index=False).encode('utf-8')

        st.download_button(
            label="ä¸‹è¼‰æ‰¹æ¬¡é æ¸¬ç¯„ä¾‹ CSV æª”æ¡ˆ",
            data=csv_template,
            file_name="prediction_template.csv",
            mime="text/csv",
            help="ä¸‹è¼‰ä¸€å€‹åŒ…å«æ‰€æœ‰é¸å®šç‰¹å¾µæ¬„ä½çš„ç©ºç™½ CSV æª”æ¡ˆï¼Œæ‚¨å¯ä»¥å¡«å…¥æ•¸æ“šå¾Œä¸Šå‚³ã€‚"
        )

        uploaded_file = st.file_uploader("ä¸Šå‚³ CSV æª”æ¡ˆ", type=["csv"])

        if uploaded_file is not None:
            try:
                batch_df_raw = pd.read_csv(uploaded_file)
                st.write("ä¸Šå‚³æª”æ¡ˆé è¦½ï¼š")
                st.write(batch_df_raw.head())

                selected_features = st.session_state['selected_features']
                uploaded_columns = batch_df_raw.columns.tolist()

                st.subheader("æ¬„ä½æ˜ å°„è¨­å®š")
                st.info("è«‹å°‡æ¨¡å‹æ‰€éœ€çš„ç‰¹å¾µï¼Œæ˜ å°„åˆ°æ‚¨ä¸Šå‚³æª”æ¡ˆä¸­å°æ‡‰çš„æ¬„ä½ã€‚å¦‚æœæŸå€‹ç‰¹å¾µåœ¨æ‚¨çš„æª”æ¡ˆä¸­ä¸å­˜åœ¨ï¼Œè«‹é¸æ“‡ 'æœªæ˜ å°„'ï¼Œç³»çµ±å°‡ä½¿ç”¨é è¨­å€¼ 0 å¡«å……ã€‚")

                column_mapping = {}
                mapping_cols = st.columns(4)
                for i, feature in enumerate(selected_features):
                    with mapping_cols[i % 4]:
                        default_index = uploaded_columns.index(feature) if feature in uploaded_columns else 0
                        column_mapping[feature] = st.selectbox(
                            f"æ¨¡å‹ç‰¹å¾µ: {feature}",
                            ['æœªæ˜ å°„'] + uploaded_columns,
                            index=default_index + 1 if feature in uploaded_columns else 0,
                            key=f"map_{feature}"
                        )
                
                if st.button("åŸ·è¡Œæ‰¹æ¬¡é æ¸¬ (å·²æ˜ å°„)"):
                    with st.spinner("æ­£åœ¨æ ¹æ“šæ˜ å°„è¨­å®šè™•ç†è³‡æ–™ä¸¦é€²è¡Œé æ¸¬..."):
                        # å»ºç«‹ç”¨æ–¼é æ¸¬çš„ DataFrame
                        batch_X_mapped = pd.DataFrame(0.0, index=batch_df_raw.index, columns=selected_features)

                        for model_feature, uploaded_col in column_mapping.items():
                            if uploaded_col != 'æœªæ˜ å°„':
                                batch_X_mapped[model_feature] = pd.to_numeric(batch_df_raw[uploaded_col], errors='coerce')
                            # å¦‚æœæ˜¯ 'æœªæ˜ å°„'ï¼Œå‰‡ä¿æŒç‚º 0.0 (é è¨­å€¼)
                        
                        # è™•ç† NaN å€¼ (å¯èƒ½ä¾†è‡ª to_numeric æˆ–æœªæ˜ å°„çš„ç‰¹å¾µ)
                        batch_X_mapped.dropna(inplace=True)

                        if batch_X_mapped.empty:
                            st.warning("é è™•ç†å¾Œï¼Œä¸Šå‚³æª”æ¡ˆä¸­æ²’æœ‰æœ‰æ•ˆè³‡æ–™å¯ä¾›é æ¸¬ã€‚è«‹æª¢æŸ¥æ‚¨çš„æ˜ å°„å’Œæ•¸æ“šã€‚")
                        else:
                            # ç¸®æ”¾è³‡æ–™
                            scaler = st.session_state['scaler']
                            batch_scaled = scaler.transform(batch_X_mapped)

                            # é æ¸¬
                            model = st.session_state['trained_model']
                            batch_predictions_encoded = model.predict(batch_scaled)

                            # è§£ç¢¼çµæœ
                            le = st.session_state['le']
                            batch_predictions_label = le.inverse_transform(batch_predictions_encoded)

                            # å°‡é æ¸¬çµæœåŠ å…¥åŸå§‹è³‡æ–™æ¡† (åªé‡å°æˆåŠŸé æ¸¬çš„è¡Œ)
                            batch_df_results = batch_df_raw.loc[batch_X_mapped.index].copy() # ç¢ºä¿ç´¢å¼•åŒ¹é…
                            batch_df_results['Predicted_Label'] = batch_predictions_label

                            st.subheader("æ‰¹æ¬¡é æ¸¬çµæœæ‘˜è¦")
                            prediction_counts = pd.Series(batch_predictions_label).value_counts()
                            st.write(prediction_counts)
                            st.bar_chart(prediction_counts)

                            st.subheader("å¸¶æœ‰é æ¸¬çµæœçš„è³‡æ–™")
                            st.dataframe(batch_df_results)

            except Exception as e:
                st.error(f"è™•ç†ä¸Šå‚³æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    st.write("---")
    if st.checkbox("é¡¯ç¤ºæ¸…ç†å¾Œçš„è³‡æ–™æ‘˜è¦"):
        st.subheader("è³‡æ–™é è¦½ (å‰ 5 ç­†)")
        st.write(df_cleaned.head())

        st.subheader("è³‡æ–™åŸºæœ¬è³‡è¨Š")
        buffer = io.StringIO()
        df_cleaned.info(buf=buffer)
        s = buffer.getvalue()
        st.text(s)

        st.subheader("æ•¸å€¼ç‰¹å¾µçµ±è¨ˆæ‘˜è¦")
        st.write(df_cleaned.describe())
else:
    st.warning("è«‹ç¢ºèª `03-01-2018.csv` å·²æ”¾ç½®åœ¨ `data` è³‡æ–™å¤¾ä¸­ã€‚")